{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from sklearn.linear_model import LogisticRegression #explicarei mais a frente o motivo de ser regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_01 = pd.read_csv('dados_pro_target_model.csv') # dados target produtividade\n",
    "data_model_02 = pd.read_csv('variáveis_explicativas_agro.csv') # variávveis explicativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_02 = data_model_02[['QV2M','T2M_RANGE']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_model = pd.merge(data_model_02, data_model_01[['Target_Produtividade']], left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_model = pd.DataFrame(dados_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## foda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explicativas = dados_model.drop(axis=1,columns='Target_Produtividade')\n",
    "resposta  = dados_model['Target_Produtividade']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['QV2M', 'T2M_RANGE', 'Target_Produtividade'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dados_model.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split ## parei aqui\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(explicativas, resposta, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((244, 2), (105, 2), (244,), (105,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m logreg \u001b[38;5;241m=\u001b[39m LogisticRegression(penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      2\u001b[0m                             dual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m      3\u001b[0m                             tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m                             warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m     14\u001b[0m                             n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mlogreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Treino\u001b[39;00m\n\u001b[0;32m     19\u001b[0m y_pred_logreg_train \u001b[38;5;241m=\u001b[39m logreg\u001b[38;5;241m.\u001b[39mpredict(x_train)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1216\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1208\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1209\u001b[0m     X,\n\u001b[0;32m   1210\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1215\u001b[0m )\n\u001b[1;32m-> 1216\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m   1219\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:216\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    208\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m ]:\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l2', \n",
    "                            dual=False, \n",
    "                            tol=0.0001, \n",
    "                            C=1, \n",
    "                            fit_intercept=True, \n",
    "                            intercept_scaling=1, \n",
    "                            class_weight=None, \n",
    "                            random_state=None, \n",
    "                            solver='liblinear', \n",
    "                            max_iter=100, \n",
    "                            multi_class='ovr', \n",
    "                            verbose=0, \n",
    "                            warm_start=False, \n",
    "                            n_jobs=-1)\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Treino\n",
    "y_pred_logreg_train = logreg.predict(x_train)\n",
    "y_score_logreg_train = logreg.predict_proba(x_train)\n",
    "\n",
    "# Teste\n",
    "y_pred_logreg_test = logreg.predict(x_test)\n",
    "y_score_logreg_test = logreg.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro: 61384.96919682279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# Divida os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(explicativas, resposta, test_size=0.3, random_state=42)\n",
    "\n",
    "# Use um modelo de regressão linear como exemplo\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Treine o modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Faça previsões\n",
    "previsoes = modelo.predict(X_test)\n",
    "\n",
    "# Avalie o desempenho do modelo (substitua pela métrica apropriada para o seu problema)\n",
    "erro = mean_squared_error(y_test, previsoes)\n",
    "\n",
    "print(f'Erro: {erro}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m modelo \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Treine o modelo\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Faça previsões\u001b[39;00m\n\u001b[0;32m     17\u001b[0m previsoes \u001b[38;5;241m=\u001b[39m modelo\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1216\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1208\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1209\u001b[0m     X,\n\u001b[0;32m   1210\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1215\u001b[0m )\n\u001b[1;32m-> 1216\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m   1219\u001b[0m multi_class \u001b[38;5;241m=\u001b[39m _check_multi_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class, solver, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:216\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    208\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m ]:\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Exemplo de dados (substitua isso pelos seus dados)\n",
    "X, y = explicativas,resposta\n",
    "# Divida os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use um modelo de Regressão Logística\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Treine o modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Faça previsões\n",
    "previsoes = modelo.predict(X_test)\n",
    "\n",
    "# Avalie o desempenho do modelo\n",
    "acuracia = accuracy_score(y_test, previsoes)\n",
    "matriz_confusao = confusion_matrix(y_test, previsoes)\n",
    "\n",
    "print(f'Acurácia: {acuracia}')\n",
    "print(f'Matriz de Confusão:\\n{matriz_confusao}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro Médio Quadrático (MSE): 140131.68890380953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Exemplo de dados (substitua isso pelos seus dados)\n",
    "X, y = explicativas,resposta\n",
    "\n",
    "# Divida os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Use um modelo de Regressão de Árvore de Decisão\n",
    "modelo = DecisionTreeRegressor()\n",
    "\n",
    "# Treine o modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Faça previsões\n",
    "previsoes = modelo.predict(X_test)\n",
    "\n",
    "# Avalie o desempenho do modelo\n",
    "erro_mse = mean_squared_error(y_test, previsoes)\n",
    "\n",
    "print(f'Erro Médio Quadrático (MSE): {erro_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro: 62116.84179849007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Exemplo de dados (substitua isso pelos seus dados)\n",
    "X, y = explicativas,resposta\n",
    "\n",
    "# Divida os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use um modelo de regressão linear como exemplo\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Treine o modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Faça previsões\n",
    "previsoes = modelo.predict(X_test)\n",
    "\n",
    "# Avalie o desempenho do modelo (substitua pela métrica apropriada para o seu problema)\n",
    "erro = mean_squared_error(y_test, previsoes)\n",
    "\n",
    "print(f'Erro: {erro}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_logreg_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Treino\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m acc_logreg_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(accuracy_score(\u001b[43my_pred_logreg_train\u001b[49m, y_train) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Teste\u001b[39;00m\n\u001b[0;32m      8\u001b[0m acc_logreg_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(accuracy_score(y_pred_logreg_test, y_test) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_logreg_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 1) Cálculo da acurácia\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Treino\n",
    "acc_logreg_train = round(accuracy_score(y_pred_logreg_train, y_train) * 100, 2)\n",
    "\n",
    "#Teste\n",
    "acc_logreg_test = round(accuracy_score(y_pred_logreg_test, y_test) * 100, 2)\n",
    "\n",
    "# 2) Cálculo da área sob curva ROC e Gini\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Treino\n",
    "fpr_logreg_train, tpr_logreg_train, thresholds = roc_curve(y_train, y_score_logreg_train[:,1])\n",
    "roc_auc_logreg_train = 100*round(auc(fpr_logreg_train, tpr_logreg_train), 2)\n",
    "gini_logreg_train = 100*round((2*roc_auc_logreg_train/100 - 1), 2)\n",
    "\n",
    "# Teste\n",
    "fpr_logreg_test, tpr_logreg_test, thresholds = roc_curve(y_test, y_score_logreg_test[:,1])\n",
    "roc_auc_logreg_test = 100*round(auc(fpr_logreg_test, tpr_logreg_test), 2)\n",
    "gini_logreg_test = 100*round((2*roc_auc_logreg_test/100 - 1), 2)\n",
    "\n",
    "\n",
    "# 3) Gráfico da curva ROC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr_logreg_train, tpr_logreg_train, color='blue',lw=lw, label='ROC (Treino = %0.0f)' % roc_auc_logreg_train)\n",
    "plt.plot(fpr_logreg_test, tpr_logreg_test, color='darkorange',lw=lw, label='ROC (Teste = %0.0f)' % roc_auc_logreg_test)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Falso Positivo', fontsize=15)\n",
    "plt.ylabel('Verdadeiro Positivo', fontsize=15)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.legend(fontsize=20) \n",
    "plt.title('Curva ROC - Modelo Titanic Kaggle', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "print('Acurácia, Gini e Área Curva ROC (Base de Treino): ',acc_logreg_train, gini_logreg_train, roc_auc_logreg_train)\n",
    "print('Acurácia, Gini e Área Curva ROC (Base de Teste): ',acc_logreg_test, gini_logreg_test, roc_auc_logreg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = svm.SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2823.76461318, 2822.59473158, 2819.874138  , 2819.75234168,\n",
       "       2822.2395503 , 2822.9827603 , 2823.25149286, 2823.11844332,\n",
       "       2822.88410276, 2821.5510595 , 2821.10486068, 2819.81771083,\n",
       "       2821.82414499, 2822.32015698, 2823.14698026, 2823.21014507,\n",
       "       2823.12804752, 2823.61921625, 2822.38042002, 2823.03615503,\n",
       "       2821.08889542, 2820.41967462, 2820.72002368, 2821.3923379 ,\n",
       "       2818.84898397, 2818.34277382, 2818.54180176, 2822.25429709,\n",
       "       2820.85817131, 2820.1395973 , 2821.97793703, 2818.18612563,\n",
       "       2823.40523027, 2821.99204116, 2820.4156398 , 2818.6261721 ,\n",
       "       2821.0523944 , 2823.24748407, 2821.79392503, 2820.47838198,\n",
       "       2822.87365341, 2821.37679674, 2821.36561826, 2821.31237215,\n",
       "       2818.67238676, 2821.64037046, 2820.30124686, 2820.53535159,\n",
       "       2823.47073292, 2822.65570919, 2821.15170238, 2820.26291547,\n",
       "       2820.74044902, 2821.84599195, 2822.62395538, 2821.84438924,\n",
       "       2822.16837284, 2823.63097155, 2823.97617814, 2823.84736252,\n",
       "       2823.19887119, 2820.86466877, 2819.882906  , 2821.94668585,\n",
       "       2822.14254981, 2819.65034862, 2819.84056783, 2820.10695226,\n",
       "       2819.86985541, 2819.79872542, 2821.35880328, 2822.19208184,\n",
       "       2822.88393302, 2822.83038212, 2822.22609688, 2821.52602826,\n",
       "       2823.37767198, 2821.00896665, 2821.17375216, 2821.95171116,\n",
       "       2823.54162229, 2823.89420561, 2823.07759422, 2823.37094309,\n",
       "       2819.04696295, 2822.72654369, 2823.18994297, 2823.89945335,\n",
       "       2824.00690204, 2823.05242725, 2823.34249943, 2823.21718689,\n",
       "       2821.99048787, 2820.65160483, 2819.49756209, 2823.09670702,\n",
       "       2824.64543717, 2824.23990973, 2823.32831981, 2818.30324809,\n",
       "       2824.41853282, 2825.92150876, 2825.61696617, 2824.44703381,\n",
       "       2823.9386447 , 2823.45576744, 2824.30954241, 2820.59740395,\n",
       "       2820.67229087, 2824.45829285, 2822.60301314, 2822.32931435,\n",
       "       2821.15614784, 2821.41858257, 2822.35222279, 2822.94894196,\n",
       "       2823.02235536, 2819.49362879, 2822.7783463 , 2823.25178881,\n",
       "       2820.32195964, 2822.43162231, 2827.04524805, 2826.51292236,\n",
       "       2823.4768264 , 2827.34252871, 2828.31771192, 2822.4684572 ,\n",
       "       2827.42901383, 2827.73933611, 2823.33402951, 2824.93846815,\n",
       "       2825.95375128, 2825.22803898, 2823.53817946, 2823.30919618,\n",
       "       2824.27440592, 2825.03282366, 2824.78359868, 2823.19564849,\n",
       "       2824.36954326, 2823.68217492, 2821.09105716, 2828.40287527,\n",
       "       2827.24527177, 2825.9516915 , 2823.79277785, 2824.88614115,\n",
       "       2826.85101943, 2822.45948682, 2824.633395  , 2825.69038673,\n",
       "       2824.10393386, 2822.94521088, 2819.34758072, 2819.88008156,\n",
       "       2822.59664105, 2821.76096212, 2820.43150872, 2822.89211988,\n",
       "       2822.53061639, 2823.46361745, 2822.77799506, 2824.23733036,\n",
       "       2824.82728667, 2825.16296656, 2825.08880446, 2826.5234617 ,\n",
       "       2826.66253057, 2826.2593357 , 2826.74375267, 2826.38739671,\n",
       "       2826.31664715, 2827.15422874, 2827.68882675, 2826.26749168,\n",
       "       2823.32936302, 2823.46494999, 2825.64318455, 2823.98916062,\n",
       "       2828.05240239, 2826.40808862, 2826.68843164, 2827.28954061,\n",
       "       2824.8699764 , 2828.14809238, 2825.11582826, 2820.0026062 ,\n",
       "       2826.01136842, 2825.67687913, 2820.26013449, 2828.4660291 ,\n",
       "       2828.03909713, 2828.5439436 , 2822.85930496, 2824.44665835,\n",
       "       2825.39629157, 2824.66001729, 2826.47175318, 2824.51473877,\n",
       "       2823.68042839, 2823.51271795, 2823.48406235, 2825.78599579,\n",
       "       2825.06866445, 2824.16778583, 2825.21823919, 2825.45093069,\n",
       "       2823.61417094, 2826.32288574, 2825.28507175, 2825.53678372,\n",
       "       2826.06529216, 2824.96258298, 2826.17910022, 2824.24376994,\n",
       "       2822.31640224, 2819.85743363, 2828.10622137, 2826.94054257,\n",
       "       2827.64329182, 2826.41667278, 2825.01935022, 2823.84369529,\n",
       "       2823.14684718, 2824.43092017, 2826.96560732, 2828.3220287 ,\n",
       "       2824.36527094, 2822.49243503, 2820.43392029, 2819.64918795,\n",
       "       2820.30684662, 2820.11849003, 2819.59894571, 2822.56104139,\n",
       "       2828.52688524, 2827.36596907, 2827.33933048, 2826.6668314 ,\n",
       "       2827.34056369, 2825.54690039, 2824.57170194, 2821.70103714,\n",
       "       2821.08378818, 2823.64147294, 2818.61944817, 2820.57924323,\n",
       "       2820.23269059, 2824.7226069 , 2824.55238748, 2818.60391444,\n",
       "       2821.60327785, 2828.34634028, 2825.1759076 , 2825.45982244,\n",
       "       2825.62117038, 2821.90744534, 2823.19784624, 2825.76958742,\n",
       "       2823.76369758, 2819.10705453, 2821.8788711 , 2819.43421735,\n",
       "       2818.48365346, 2818.39960867, 2822.12002367, 2823.58761   ,\n",
       "       2819.52466641, 2822.96437085, 2823.01800495, 2823.42589174,\n",
       "       2821.40144643, 2821.93058288, 2819.09868722, 2818.44800743,\n",
       "       2819.01664323, 2820.6413818 , 2819.06992085, 2822.89337259,\n",
       "       2821.9812148 , 2822.80833358, 2820.49367415, 2824.48446111,\n",
       "       2823.28120118, 2822.96319469, 2823.85277053, 2821.63535078,\n",
       "       2820.43641188, 2820.08650682, 2819.7487733 , 2826.27108689,\n",
       "       2822.49486222, 2823.20609597, 2820.1015031 , 2822.502621  ,\n",
       "       2818.89630059, 2820.34979468, 2823.05129245, 2820.62713933,\n",
       "       2820.47993643, 2823.31886081, 2823.57820375, 2822.87272576,\n",
       "       2823.24589961, 2822.42146291, 2822.32049873, 2822.71604727,\n",
       "       2824.77333887, 2821.69343701, 2822.67507125, 2820.42959169,\n",
       "       2818.51694618, 2818.49479715, 2818.91926752, 2820.86619089,\n",
       "       2823.2060986 , 2820.84278856, 2820.07611512, 2821.24422174,\n",
       "       2820.35246125, 2821.83770426, 2826.70954227, 2818.95719834,\n",
       "       2823.59573427, 2821.38355164, 2823.18669499, 2823.2058803 ,\n",
       "       2821.97624876, 2819.56283273, 2819.90147764, 2822.12492003,\n",
       "       2823.63389981, 2822.92088677, 2823.07469798, 2821.26233618,\n",
       "       2823.53605595, 2820.82756734, 2821.64450227, 2823.15038773,\n",
       "       2823.07594218, 2822.95998272, 2823.21441213, 2822.60359158,\n",
       "       2821.28506105, 2818.96448645, 2820.49701095, 2823.39325438,\n",
       "       2822.90111052])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(explicativas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Modelo': ['Naive Bayes', \n",
    "              'Regressão Logística',\n",
    "              'Support Vector Machines',\n",
    "              'Decision Tree', \n",
    "              'Random Forest', \n",
    "              'Gradient Boosting', \n",
    "              'k-Nearest Neighbors', \n",
    "              'Perceptron', \n",
    "              'Rede Neural (MLP)',\n",
    "              'STACKING',\n",
    "              'BLENDING'              \n",
    "              ],\n",
    "    \n",
    "     'Gini_Treino': [gini_gaussian_train,\n",
    "                    gini_logreg_train,\n",
    "                    gini_svc_train,\n",
    "                    gini_dectree_train,\n",
    "                    gini_rndforest_train,\n",
    "                    gini_gbc_train,\n",
    "                    gini_knn_train,\n",
    "                    gini_perceptron_train,\n",
    "                    gini_mlp_train,\n",
    "                    gini_stk_train,\n",
    "                    gini_blend_train],   \n",
    "    \n",
    "    \n",
    "    'Gini_Teste': [gini_gaussian_test,\n",
    "                    gini_logreg_test,\n",
    "                    gini_svc_test,\n",
    "                    gini_dectree_test,\n",
    "                    gini_rndforest_test,\n",
    "                    gini_gbc_test,\n",
    "                    gini_knn_test,\n",
    "                    gini_perceptron_test,\n",
    "                    gini_mlp_test,\n",
    "                    gini_stk_test,\n",
    "                    gini_blend_test]\n",
    "\n",
    "})\n",
    "models['Delta'] = models['Gini_Treino'] - models['Gini_Teste']\n",
    "model_comp = models.sort_values(by='Gini_Teste', ascending=False)\n",
    "model_comp = model_comp[['Modelo','Gini_Treino','Gini_Teste','Delta']]\n",
    "\n",
    "\n",
    "model_comp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
